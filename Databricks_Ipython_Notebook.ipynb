{"cells":[{"cell_type":"markdown","source":["### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:"],"metadata":{}},{"cell_type":"code","source":["# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression , RandomForestClassifier , DecisionTreeClassifier , MultilayerPerceptronClassifier\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_b52a0b3d(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '29ed2398afbc40789d5dd57b0df07ede')\n    hconf.set(prefix + '.username', '9690261a6dfb48bfb72b94e07ad34f24')\n    hconf.set(prefix + '.password', 'DAhp{2JtXY=[a!1#')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_b52a0b3d(name)\n\nspark = SparkSession.builder.getOrCreate()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":["csv= sqlContext.sql(\"Select * from nymc_csv\");\ncsv.show(2);\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data = sqlContext.sql(\"select Borough, NUMBEROFPERSONSINJURED + NUMBEROFPERSONSKILLED + NUMBEROFPEDESTRIANSINJURED + NUMBEROFPEDESTRIANSKILLED +NUMBEROFCYCLISTINJURED + NUMBEROFMOTORISTINJURED + NUMBEROFMOTORISTKILLED as Incidents from ppp\");\n\nindexer= StringIndexer(inputCol=\"Borough\", outputCol=\"indx_borough\")\nindexed= indexer.fit(data).transform(data)\nindx_feat=indexed.select(\"indx_borough\", col(\"Incidents\").alias(\"label\"))\n\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Select features and label\n'''data = csv.select(\"Borough\", \"VEHICLETYPECODE 1\", ((col(\"Incidets\")).cast(\"Int\").alias(\"label\")))'''\n\n# Split the data\nsplits = indx_feat.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()\nprint \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows\ntrain.show(10)\ntest.show(10)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":["vectorAssembler = VectorAssembler(inputCols=[\"indx_borough\"], outputCol=\"features\")\ndt = RandomForestClassifier(labelCol=\"label\", featuresCol= \"features\")\npipeline = Pipeline(stages=[vectorAssembler, dt])"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["model = pipeline.fit(train)\n\npredictions1 = model.transform(test)\npredictions1.select(\"*\").show(100)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["evaluator= MulticlassClassificationEvaluator()\n.setLabelCol(\"trueLabel\")\n.setPredictionCol(\"prediction\")\n.setMetricName(\"accuracy\")\ntreeModel = model.stages[1]\n\nprint \"Learned classification tree model:\" , treeModel \naccuracy = evaluator.evaluate(predictions1)\nprint \"Average Accuracy =\", accuracy\nprint \"Test Error = \" , (1.0 - accuracy)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["vectorAssembler = VectorAssembler(inputCols=[\"indx_borough\"], outputCol=\"features\")\ndt = LogisticRegression(labelCol=\"label\", featuresCol= \"features\")\npipeline = Pipeline(stages=[vectorAssembler, dt])\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["model = pipeline.fit(train)\n\npredictions = model.transform(test)\npredictions.select(\"*\").show(100)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["evaluator= MulticlassClassificationEvaluator()\n.setLabelCol(\"trueLabel\")\n.setPredictionCol(\"prediction\")\n.setMetricName(\"accuracy\")\ntreeModel = model.stages[1]\n\nprint \"Learned classification tree model:\" , treeModel \naccuracy = evaluator.evaluate(predictions)\nprint \"Average Accuracy =\", accuracy\nprint \"Test Error = \" , (1.0 - accuracy)\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["vectorAssembler = VectorAssembler(inputCols=[\"indx_borough\"], outputCol=\"features\")\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol= \"features\")\npipeline = Pipeline(stages=[vectorAssembler, dt])\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["model = pipeline.fit(train)\n\npredictions = model.transform(test)\npredictions.select(\"*\").show(100)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator()\n.setLabelCol(\"trueLabel\")\n.setPredictionCol(\"prediction\")\n.setMetricName(\"accuracy\")\ntreeModel = model.stages[1]\n\nprint \"Learned classification tree model:\" , treeModel \naccuracy = evaluator.evaluate(predictions)\nprint \"Average Accuracy =\", accuracy\nprint \"Test Error = \", (1 - accuracy)\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"Midterm2 Python+Classfication+Parameter+Tuning","notebookId":2189070968252420},"nbformat":4,"nbformat_minor":0}
