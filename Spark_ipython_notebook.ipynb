{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"http://www.calstatela.edu/centers/hipic\"><img align=\"left\" src=\"https://avatars2.githubusercontent.com/u/4156894?v=3&s=100\"><image/>\n",
    "</a>\n",
    "## CIS5560 Term Project Tutorial\n",
    "<img align=\"center\" alt=\"California State University, Los Angeles\" src=\"http://www.calstatela.edu/sites/default/files/groups/California%20State%20University%2C%20Los%20Angeles/master_logo_full_color_horizontal_centered.svg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "#### Authors: [Prathibha Gubbi Prakash](https://www.linkedin.com/in/prathibha-gubbi-prakash-0532a4124); [Anusha Manjappa](https://www.linkedin.com/in/anusha-manjappa-5a28a076); [Srihitha Reddy Sivannagari](https://www.linkedin.com/in/srihitha-reddy-sivannagari-044448105)\n",
    "\n",
    "#### Instructor: [Jongwook Woo](https://www.linkedin.com/in/jongwook-woo-7081a85)\n",
    "\n",
    "#### Date: 05/19/2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictive analysis of Newyork motor cycle collisions\n",
    "\n",
    "Predictive analysis of various elements associated with motorcycle accidents in New York city like borough, kind of vehicle, contributing factor of the accident, count of accidents in a particular area and factors contributing to those accidents based on available features in the data set using Machine Learning Algorithms with tools like AzureML and SparkML.\n",
    "\n",
    "## Creating a Classification Model using Random forest classifier, Decision tree classifier, Logistic regression\n",
    "\n",
    "In this notebook, we will implement three types of classification model using *Random forest classifier*, *Decision tree classifier*, *LogisticRegression* that uses features of a Newyork motorcycle collision data to predict the number of accidents that took place in each borough in newyork state.\n",
    "\n",
    "### Steps to build, train and test the model from the dataset:\n",
    "\n",
    "1. Import the libraries you will need and prepare the training and test data \n",
    "2. Load the source data into table\n",
    "3. Prepare the data with the features (input columns, output column as label)\n",
    "4. Split the data using data.randomSplit(): Training and Testing\n",
    "5. Transform the columns to a vector using VectorAssembler\n",
    "6. set features and label from the vector\n",
    "7. Define a pipeline that creates a feature vector \n",
    "7. Build a Model with the label and features\n",
    "8. Train the model\n",
    "9. Prepare the testing Data Frame with features and label from the vector; Rename label to trueLabel\n",
    "10. Predict and test the testing Data Frame using the model trained at the step 8\n",
    "11. Compare the predicted result and trueLabel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Spark SQL and Spark ML Libraries\n",
    "\n",
    "First, import the libraries you will need and prepare the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Spark SQL and Spark ML libraries\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression , RandomForestClassifier , DecisionTreeClassifier , MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Data\n",
    "1. The data for this exercise is provided as a CSV file containing details of Newyork motorcycle collisions. The data includes specific characteristics (or *features*) for each Accidents, as well as a column indicating how many Accidents occured in each borough along with date time factors. It also records the vehicle type invloved in accidents, contributing factors, SeverityOfInjury and so on. we will load this data into a DataFrame and display it.\n",
    "\n",
    "2. We load this data into tables on databricks and make necessary changes to the columns data type.\n",
    "\n",
    "3. we then use sqlContext to select and view sample data on databricks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv= sqlContext.sql(\"Select * from nymc_csv\");\n",
    "csv.show(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting labels and features\n",
    "\n",
    "For this experiment we choose borough as our feature, this column was a categorical column of type string. So we had to use <i><strong> StringIndexer </strong> </i>  to provide indices to these feature column.\n",
    "Secondly, we introduced a derived column in our dataset which is the sum of all type of accidents corresponding to each row.\n",
    "(Incidents = NUMBEROFPERSONSINJURED + NUMBEROFPERSONSKILLED + NUMBEROFPEDESTRIANSINJURED + NUMBEROFPEDESTRIANSKILLED +NUMBEROFCYCLISTINJURED + NUMBEROFMOTORISTINJURED + NUMBEROFMOTORISTKILLED).\n",
    "We used this derived column as our label and further trained this using classification model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sqlContext.sql(\"select Borough, NUMBEROFPERSONSINJURED + NUMBEROFPERSONSKILLED + NUMBEROFPEDESTRIANSINJURED + NUMBEROFPEDESTRIANSKILLED +NUMBEROFCYCLISTINJURED + NUMBEROFMOTORISTINJURED + NUMBEROFMOTORISTKILLED as Incidents from ppp\");\n",
    "\n",
    "indexer= StringIndexer(inputCol=\"Borough\", outputCol=\"indx_borough\")\n",
    "indexed= indexer.fit(data).transform(data)\n",
    "\n",
    "# rename the Incidents column to label\n",
    "indx_feat=indexed.select(\"indx_borough\", col(\"Incidents\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "\n",
    "It is common practice when building supervised machine learning models to split the source data, using some of it to train the model and reserving some to test the trained model. In this exercise, we will use 70% of the data for training, and reserve 30% for testing. In the testing data, the **label** column is renamed to **trueLabel** so we can use it later to compare predicted labels with known actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "splits = indx_feat.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train = train.count()\n",
    "test = test.count()\n",
    "print \"Training data:\", train\n",
    "print \"Testing data:\", test\n",
    "train.show(10)\n",
    "test.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the feature columns into a vector\n",
    "\n",
    "To train the classification model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"indx_borough\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Classification Model : RandomForestClassifier\n",
    "Next, you need to train a classification model using the training data. To do this, create an instance of the classification algorithm you want to use and use its **fit** method to train a model based on the training DataFrame. In this exercise, you will use a *Logistic Regression* classification algorithm - though you can use the same technique for any of the classification algorithms supported in the spark.ml API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build RandomForestClassifier model with features and label\n",
    "\n",
    "dt_1 = RandomForestClassifier(labelCol=\"label\", featuresCol= \"features\")\n",
    "pipeline_1 = Pipeline(stages=[vectorAssembler, dt_1])\n",
    "\n",
    "# train a model based on the training DataFrame\n",
    "model_1 = pipeline_1.fit(train)\n",
    "print \"First Model trained!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model :RandomForestClassifier\n",
    "\n",
    "Now you're ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict delay status for flights where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted status to the actual status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_1 = model_1.transform(test)\n",
    "predictions_1.select(\"prediction\", \"trueLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Evaluation : RandomForestClassifier\n",
    "\n",
    "As we have used Multiclass classification model, we calculated the accurracy and test error of our model using <strong>MulticlassClassificationEvaluator</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator_1= MulticlassClassificationEvaluator()\n",
    ".setLabelCol(\"trueLabel\")\n",
    ".setPredictionCol(\"prediction\")\n",
    ".setMetricName(\"accuracy\")\n",
    "treeModel_1 = model_1.stages[1]\n",
    "\n",
    "print \"Learned classification tree model:\" , treeModel \n",
    "accuracy_1 = evaluator.evaluate(predictions_1)\n",
    "print \"Average Accuracy =\", accuracy_1\n",
    "print \"Test Error = \" , (1.0 - accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result : <strong>RandomForestClassifier</strong>\n",
    "\n",
    "Average Accuracy = 0.859718490594\n",
    "\n",
    "Test Error =  0.140281509406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Classification Model : LogisticRegression\n",
    "Next, you need to train a classification model using the training data. To do this, create an instance of the classification algorithm you want to use and use its **fit** method to train a model based on the training DataFrame. In this exercise, you will use a *Logistic Regression* classification algorithm - though you can use the same technique for any of the classification algorithms supported in the spark.ml API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build LogisticRegression model with features and label\n",
    "\n",
    "dt_2 = LogisticRegression(labelCol=\"label\", featuresCol= \"features\")\n",
    "pipeline_2 = Pipeline(stages=[vectorAssembler, dt_2])\n",
    "\n",
    "# train a model based on the training DataFrame\n",
    "model_2 = pipeline_2.fit(train)\n",
    "print \"Second Model trained!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model : LogisticRegression\n",
    "\n",
    "Now you're ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict delay status for flights where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted status to the actual status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_2 = model_2.transform(test)\n",
    "predictions_2.select(\"prediction\", \"trueLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Evaluation : LogisticRegression\n",
    "\n",
    "As we have used Multiclass classification model, we calculated the accurracy and test error of our model using <strong>MulticlassClassificationEvaluator</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator_2= MulticlassClassificationEvaluator()\n",
    ".setLabelCol(\"trueLabel\")\n",
    ".setPredictionCol(\"prediction\")\n",
    ".setMetricName(\"accuracy\")\n",
    "treeModel_2 = model_2.stages[1]\n",
    "\n",
    "print \"Learned classification tree model:\" , treeModel \n",
    "accuracy_2 = evaluator.evaluate(predictions_2)\n",
    "print \"Average Accuracy =\", accuracy_2\n",
    "print \"Test Error = \" , (1.0 - accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result : <strong>LogisticRegression</strong>\n",
    "\n",
    "Average Accuracy = 0.851718490594\n",
    "\n",
    "Test Error =  0.1418201509406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Classification Model : DecisionTreeClassifier\n",
    "\n",
    "Next, you need to train a classification model using the training data. To do this, create an instance of the classification algorithm you want to use and use its **fit** method to train a model based on the training DataFrame. In this exercise, you will use a *Logistic Regression* classification algorithm - though you can use the same technique for any of the classification algorithms supported in the spark.ml API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build DecisionTreeClassifier model with features and label\n",
    "\n",
    "dt_3 = DecisionTreeClassifier(labelCol=\"label\", featuresCol= \"features\")\n",
    "pipeline_3 = Pipeline(stages=[vectorAssembler, dt_3])\n",
    "\n",
    "# train a model based on the training DataFrame\n",
    "model_3 = pipeline_3.fit(train)\n",
    "print \"Third Model trained!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model : DecisionTreeClassifier\n",
    "\n",
    "Now you're ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict delay status for flights where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted status to the actual status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_3 = model_3.transform(test)\n",
    "predictions_3.select(\"prediction\", \"trueLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Evaluation : DecisionTreeClassifier\n",
    "\n",
    "As we have used Multiclass classification model, we calculated the accurracy and test error of our model using <strong>MulticlassClassificationEvaluator</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator_3 = MulticlassClassificationEvaluator()\n",
    ".setLabelCol(\"trueLabel\")\n",
    ".setPredictionCol(\"prediction\")\n",
    ".setMetricName(\"accuracy\")\n",
    "treeModel_3 = model_3.stages[1]\n",
    "\n",
    "print \"Learned classification tree model:\" , treeModel \n",
    "accuracy_3 = evaluator.evaluate(predictions_3)\n",
    "print \"Average Accuracy =\", accuracy_3\n",
    "print \"Test Error = \", (1 - accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result : <strong>DecisionTreeClassifier</strong>\n",
    "\n",
    "Average Accuracy = 0.858718490594\n",
    "\n",
    "Test Error =  0.141281509406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Best model \n",
    "\n",
    "All three models gave almost same accuracyy value with slight variation in the precision value.\n",
    "Random forest classifier is slightly better than other two models, because of higher accuracy rate of **85.9%**.\n",
    "\n",
    "(Since it is a multiclass classification we don't get TP,TN,FP,FN values hence we cannot calculate precission and recall value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. [https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95  ](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95  )\n",
    "1. [https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-jupyter-spark-sql](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-jupyter-spark-sql)\n",
    "1. [https://spark.apache.org/docs/1.6.1/ml-classification-regression.html](https://spark.apache.org/docs/1.6.1/ml-classification-regression.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}